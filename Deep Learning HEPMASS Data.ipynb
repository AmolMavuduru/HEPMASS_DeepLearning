{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for High Energy Particle Physics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "//anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('all_train.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># label</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.346368</td>\n",
       "      <td>0.416306</td>\n",
       "      <td>0.999236</td>\n",
       "      <td>0.475342</td>\n",
       "      <td>0.427493</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>1.989833</td>\n",
       "      <td>0.344530</td>\n",
       "      <td>1.566297</td>\n",
       "      <td>...</td>\n",
       "      <td>4.105282</td>\n",
       "      <td>0.267826</td>\n",
       "      <td>0.378718</td>\n",
       "      <td>1.743123</td>\n",
       "      <td>3.406367</td>\n",
       "      <td>4.350537</td>\n",
       "      <td>-0.352571</td>\n",
       "      <td>1.130032</td>\n",
       "      <td>2.227706</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.708236</td>\n",
       "      <td>-0.319394</td>\n",
       "      <td>-1.241873</td>\n",
       "      <td>-0.887231</td>\n",
       "      <td>-0.871906</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>-0.001047</td>\n",
       "      <td>-1.038225</td>\n",
       "      <td>0.655748</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.178141</td>\n",
       "      <td>-0.877361</td>\n",
       "      <td>-1.483769</td>\n",
       "      <td>-0.573682</td>\n",
       "      <td>-1.693781</td>\n",
       "      <td>-0.545062</td>\n",
       "      <td>-0.299118</td>\n",
       "      <td>-0.662942</td>\n",
       "      <td>-0.193019</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.360693</td>\n",
       "      <td>1.794174</td>\n",
       "      <td>0.264738</td>\n",
       "      <td>-0.472273</td>\n",
       "      <td>-0.292344</td>\n",
       "      <td>-1.054221</td>\n",
       "      <td>-1.150495</td>\n",
       "      <td>1.423404</td>\n",
       "      <td>1.270098</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.199511</td>\n",
       "      <td>0.539020</td>\n",
       "      <td>-1.590629</td>\n",
       "      <td>-0.573682</td>\n",
       "      <td>-0.543636</td>\n",
       "      <td>-0.937456</td>\n",
       "      <td>-0.300344</td>\n",
       "      <td>-0.523262</td>\n",
       "      <td>-1.506304</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.377914</td>\n",
       "      <td>-0.103932</td>\n",
       "      <td>-0.649434</td>\n",
       "      <td>-2.125015</td>\n",
       "      <td>-1.643797</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>1.011112</td>\n",
       "      <td>-1.040340</td>\n",
       "      <td>-0.541991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463763</td>\n",
       "      <td>-0.006583</td>\n",
       "      <td>1.089122</td>\n",
       "      <td>-0.573682</td>\n",
       "      <td>-0.276348</td>\n",
       "      <td>-0.409272</td>\n",
       "      <td>-0.349926</td>\n",
       "      <td>-0.307123</td>\n",
       "      <td>0.529698</td>\n",
       "      <td>1250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.067436</td>\n",
       "      <td>-0.636762</td>\n",
       "      <td>-0.620166</td>\n",
       "      <td>-0.062551</td>\n",
       "      <td>1.588715</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>-0.595304</td>\n",
       "      <td>-1.238987</td>\n",
       "      <td>0.336844</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.552837</td>\n",
       "      <td>-1.418494</td>\n",
       "      <td>-0.562982</td>\n",
       "      <td>1.743123</td>\n",
       "      <td>0.881802</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>1.560950</td>\n",
       "      <td>-0.150760</td>\n",
       "      <td>-1.023889</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # label        f0        f1        f2        f3        f4        f5  \\\n",
       "0      1.0 -0.346368  0.416306  0.999236  0.475342  0.427493 -0.005984   \n",
       "1      1.0  1.708236 -0.319394 -1.241873 -0.887231 -0.871906 -0.005984   \n",
       "2      0.0 -0.360693  1.794174  0.264738 -0.472273 -0.292344 -1.054221   \n",
       "3      1.0 -0.377914 -0.103932 -0.649434 -2.125015 -1.643797 -0.005984   \n",
       "4      0.0 -0.067436 -0.636762 -0.620166 -0.062551  1.588715 -0.005984   \n",
       "\n",
       "         f6        f7        f8   ...         f18       f19       f20  \\\n",
       "0  1.989833  0.344530  1.566297   ...    4.105282  0.267826  0.378718   \n",
       "1 -0.001047 -1.038225  0.655748   ...   -1.178141 -0.877361 -1.483769   \n",
       "2 -1.150495  1.423404  1.270098   ...   -1.199511  0.539020 -1.590629   \n",
       "3  1.011112 -1.040340 -0.541991   ...    0.463763 -0.006583  1.089122   \n",
       "4 -0.595304 -1.238987  0.336844   ...   -0.552837 -1.418494 -0.562982   \n",
       "\n",
       "        f21       f22       f23       f24       f25       f26    mass  \n",
       "0  1.743123  3.406367  4.350537 -0.352571  1.130032  2.227706  1000.0  \n",
       "1 -0.573682 -1.693781 -0.545062 -0.299118 -0.662942 -0.193019   750.0  \n",
       "2 -0.573682 -0.543636 -0.937456 -0.300344 -0.523262 -1.506304   750.0  \n",
       "3 -0.573682 -0.276348 -0.409272 -0.349926 -0.307123  0.529698  1250.0  \n",
       "4  1.743123  0.881802  0.002516  1.560950 -0.150760 -1.023889   750.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train['mass'] = scaler.fit_transform(train['mass'].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = train.drop(['# label'], axis=1)\n",
    "y = train['# label']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4900000 entries, 4642813 to 6413414\n",
      "Data columns (total 28 columns):\n",
      "f0      float64\n",
      "f1      float64\n",
      "f2      float64\n",
      "f3      float64\n",
      "f4      float64\n",
      "f5      float64\n",
      "f6      float64\n",
      "f7      float64\n",
      "f8      float64\n",
      "f9      float64\n",
      "f10     float64\n",
      "f11     float64\n",
      "f12     float64\n",
      "f13     float64\n",
      "f14     float64\n",
      "f15     float64\n",
      "f16     float64\n",
      "f17     float64\n",
      "f18     float64\n",
      "f19     float64\n",
      "f20     float64\n",
      "f21     float64\n",
      "f22     float64\n",
      "f23     float64\n",
      "f24     float64\n",
      "f25     float64\n",
      "f26     float64\n",
      "mass    float64\n",
      "dtypes: float64(28)\n",
      "memory usage: 1.1 GB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training a Deep Neural Network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 56)                1624      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 56)                3192      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 112)               6384      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 56)                6328      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 56)                3192      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 28)                1596      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 29        \n",
      "=================================================================\n",
      "Total params: 24,781\n",
      "Trainable params: 24,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 4900000 samples, validate on 2100000 samples\n",
      "Epoch 1/5\n",
      "4900000/4900000 [==============================] - 295s - loss: 0.2981 - acc: 0.8614 - val_loss: 0.2817 - val_acc: 0.8710\n",
      "Epoch 2/5\n",
      "4900000/4900000 [==============================] - 301s - loss: 0.2813 - acc: 0.8717 - val_loss: 0.2774 - val_acc: 0.8744\n",
      "Epoch 3/5\n",
      "4900000/4900000 [==============================] - 304s - loss: 0.2780 - acc: 0.8736 - val_loss: 0.2756 - val_acc: 0.8753\n",
      "Epoch 4/5\n",
      "4900000/4900000 [==============================] - 327s - loss: 0.2765 - acc: 0.8745 - val_loss: 0.2740 - val_acc: 0.8759\n",
      "Epoch 5/5\n",
      "4900000/4900000 [==============================] - 294s - loss: 0.2756 - acc: 0.8751 - val_loss: 0.2736 - val_acc: 0.8764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x122034d68>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.regularizers import l2 # L2 regularization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "L2_CONSTANT = 1e-7 # L2 regularization constant\n",
    "hidden_layer_sizes = [28, 28, 56, 56, 112, 56, 56, 28, 28]\n",
    "\n",
    "# Model definition\n",
    "model = Sequential()\n",
    "first = True\n",
    "for hidden_layer_size in hidden_layer_sizes:\n",
    "    if first:\n",
    "        model.add(Dense(hidden_layer_size, \n",
    "                        activation='sigmoid', \n",
    "                        input_dim=28, kernel_regularizer=l2(L2_CONSTANT)))\n",
    "    else:\n",
    "        model.add(Dense(hidden_layer_size, \n",
    "                        activation='sigmoid', \n",
    "                        kernel_regularizer=l2(L2_CONSTANT)))\n",
    "        \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=1, mode='min')\n",
    "\n",
    "# compiling model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# fitting model\n",
    "model.fit(X_train.values, y_train.values, validation_data=(X_valid.values, y_valid.values), epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
